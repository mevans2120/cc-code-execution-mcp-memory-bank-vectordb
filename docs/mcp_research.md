# Research: Code Execution with MCP & Agent Usability

## Overview
This document analyzes the concept of "Code Execution with MCP" (Model Context Protocol) as described by Anthropic, and explores how to make MCP servers highly usable by AI agents. The core premise is shifting from **direct tool calling** (where the model calls one tool at a time) to **code execution** (where the model writes scripts to interact with tools).

## Core Concept: From Tool Calling to Code Execution

Traditionally, agents interact with MCP servers by:
1.  Receiving a list of all available tools (consuming context).
2.  Calling a tool and waiting for the result.
3.  Receiving the result (consuming context).
4.  Repeating for subsequent steps.

**Code Execution with MCP** proposes that agents should instead:
1.  Discover tools dynamically (e.g., via filesystem or search).
2.  Write a script (e.g., TypeScript or Python) that imports and uses these tools.
3.  Execute the script in a sandboxed environment.
4.  Receive the final output.

## Ideas for Agent Usability

To make your `claude-code-vectordb` (and future MCP servers) highly usable by agents, consider the following patterns:

### 1. "Tools as Code" Structure
Instead of just defining JSON schemas, structure your server's capabilities as a client library that can be imported.
*   **Idea**: Expose a clean TypeScript/JavaScript API that mirrors your MCP tools.
*   **Example**:
    ```typescript
    import { queryVectorDb } from './servers/vectordb';
    
    const results = await queryVectorDb({ query: "auth patterns", limit: 10 });
    const relevant = results.filter(r => r.score > 0.8);
    console.log(relevant);
    ```

### 2. Dynamic Tool Discovery (`search_tools`)
Prevent context bloating by not listing *every* tool in the initial system prompt.
*   **Idea**: Implement a `search_tools` tool.
*   **Usage**: The agent starts with only `search_tools`. If it needs to "query a database", it calls `search_tools("database")` and receives the specific definitions for `query_vector_db`.
*   **Benefit**: Drastically reduces initial token load, especially as your server grows.

### 3. Progressive Disclosure via Filesystem
If the agent has filesystem access, map your tools to a virtual or real directory structure.
*   **Idea**: `servers/vectordb/index.ts` contains the tool definitions.
*   **Usage**: The agent can `ls servers/vectordb` to see what's available and `read servers/vectordb/query.ts` to understand the specific API.

### 4. Batch & Logic Operations
Enable the agent to perform complex logic on the server side (or in the sandbox) to avoid round-trips.
*   **Idea**: Ensure your API supports batch operations or that your "Code Mode" allows the agent to loop over data.
*   **Context**: For your Vector DB, an agent might want to "find all documents about X, then for each document, update its metadata." In standard MCP, this is N+1 tool calls. In Code Mode, it's 1 script.

### 5. State Persistence
Allow the agent to save its work.
*   **Idea**: Provide a "workspace" directory where the agent can write intermediate files (CSVs, JSONs) and read them back later.

## Pros and Cons of Code Execution Approach

### Pros

| Category | Benefit |
| :--- | :--- |
| **Efficiency** | **98%+ Token Reduction**: Agents don't need to see every tool definition or every intermediate result. Only the final answer enters the context. |
| **Latency** | **Faster Execution**: Eliminates the "Call Tool -> Wait -> LLM Think -> Call Next Tool" loop. A single script executes all logic at machine speed. |
| **Privacy** | **Data Isolation**: Sensitive data (e.g., PII in a database) can be processed by the script and filtered *before* it is shown to the LLM. The LLM only sees the safe summary. |
| **Capability** | **Complex Logic**: Agents can use loops, conditionals (`if/else`), and error handling in code, which is much more robust than trying to "reason" through a chain of tool calls. |
| **Reusability** | **Skills**: Successful scripts can be saved as "Skills" (e.g., `summarize_daily_logs.ts`) and reused later without re-generating the code. |

### Cons

| Category | Drawback |
| :--- | :--- |
| **Complexity** | **Infrastructure Overhead**: Requires a secure, sandboxed code execution environment (e.g., Docker container, Firecracker microVM) to run the agent's code safely. |
| **Security** | **Risk of Harm**: Executing arbitrary code generated by an LLM is inherently risky. Strict sandboxing and resource limits are mandatory. |
| **Error Handling** | **Debugging**: If the agent's script fails, it needs to be able to read the error and debug it. This can sometimes lead to "debugging loops" that consume tokens. |
| **Adoption** | **Client Support**: Not all MCP clients currently support "Code Mode" or have a built-in execution environment. It requires a specific client setup (like the one Anthropic describes). |

## Recommendations for `claude-code-vectordb`

Given your current setup:

1.  **Keep the Standard MCP Server**: Your current `index.ts` is solid for standard clients. Don't replace it.
2.  **Add a "Client SDK"**: Create a simple wrapper (e.g., in `src/lib/agent-sdk.ts`) that exports your functions (`query`, `addDocuments`) as standard async JavaScript functions. This prepares you for "Code Mode" clients.
3.  **Implement `search_tools`**: This is a low-hanging fruit. Add a tool that lets an agent search your existing tool descriptions. This makes your server "agent-friendly" for standard clients that want to save context.
